- when a file is modified check what is in it changed, just extract that part ✅
- do we require inotify API? (will consider after creating the main logic) ✅
- fixed size chunking ✅
- content defined chunking
- breaking file into chunks✅
- where will we save the chunks & the previous state -> snap-file.json ✅
- comparing chunked hashes ✅
- hashing(crypto) ✅
 detecting if something has changed in the folder/file ✅
- using inotify api check which file is changed then compare both the states using the chunks and take out the changed ones ✅
- but the problem is that the program runs continously watching files
- which will be better if on changing files run the program and on basis of it will sync to server or watch continously and as soon as change received then sync it(but works for every byte , debouncing like logic will be required here) ✅ (used hybrid approach by considering both)

- map stores all the file snaps, ❌(it is must)
- for every change it resets the whole SNAP_FILE ✅ 
- if a file changes then extract that file's chunks, compare every chunk and replace only that changed chunks in the SNAP_FILE ❌ (not possible for .json)

CDC(content defined chunking)
- fixed size chunking fails to correctly identifies the changed chunk as the chunks afterwards also shifts  so using CDC ✅
- chunks are created using (hash % N == 0), if this condition met for a window ✅
- 2 important vars, N and window size ✅
- chunks can be of ~N size but not ==N ✅
- used hybrid approach of weak + strong hash where weak hash finds boundary and strong hash for saving actual hash of chunk

- in case of just rename not deletion then instead of sending file, rename in the server too!! ✅
- compare changes optimally ✅
- track renamed files and send ✅
- will we save the rename state in the snap-file? ❌
- how to send the rename state with the snapshot? ✅
- how to single update when multiple rename of the same file? ❌
- instead of logging now we have to return the changed parts for syncing ✅
- create a minimal version where client on detecting changes using inotify syncs to server 
✅

- how the debouncing works here?

- have to clean/filter unnecessary or duplicate events like:
for same file MODIFY + DELETE then consider DELETE, for same file MODIFY + MODIFY + ... + MODIFY then consider the last one
. one approach can be spawn a thread where main thread will take out events and side by side child thread will clean the events

- optimise fileio class for removing/adding & modifying specific chunks
given offset and chunk_size
. remove bytes from j index to last, ftruncate!!
. add chars from offset to offset+chunk_size-1
. this can only be done via creating a temp file as doing these operations not possible for files
. but have to optimise as if multiple chunks are to be sent then for each cunk a temp file will be created/destroyed so need to understand when to create/destroy temp file

- add a class for handling different types of messages for client side✅
- add a class for handling different types of message for server side 

- create the whole logic of server side to handle chunks writes, chunk deletes

modification: ✅
. old chunk offset + size to remove the chunk and new chunk's offset + size to extract from file and replace with.
addition: ✅
. take new chunk's offset + size to extract from file and append the data of new chunk
deletion: ✅
. take end index of the old chunk to truncate file
. suppose 5 chunks removed so take the end index of the first removed chunk 
- addition/deletion only one will exist at a time ✅

- initially any peer should know what to send/receive before watching for events as there can be changes when program was closed.
- lets say some files were modifed, few were removed, few were created then how this info will be sent as we  have different message types for these (using SYNC_SESSION) 

- how server should handle multiple modify chunks of same file 
. by keeping a file pointer which opens a file and not closes till any other file's chunk come
. but issue is when to detect that this is the last modify chunk received ✅ (added is_last_chunk prop)

chunk:{               
    offset,
    chunk_size,
    hash,
    chunk_no
}       
what change can be tolerated-  
. offset,
. chunk_no

what change is proper sign of modification-
. hash
. chunk_size(but will not consider for check, hash is reliable)

prev_snap: C1, C2, C3, C4, C5, C6,
curr_snap: C1', C2, C3, C4', C5
C6=C5
C4 & C5 changed and new C4' is there
C3=C3
C2=C2
C1


ek efficient data structure chaiye in operations ke liye- 
dekh bro mujhe objects store krne hain with properties:
    size_t offset;
    size_t chunk_size;
    std::string hash;
    int chunk_no;
second thing is, do we will have two version prev_snap &  curr_snap we have to compare both versions on basis of hash prop, will do these operations:
. take prev_snap object and find using its hash that is there an object in curr_snap with this hash
. take curr_snap object and find using its hash that is there an object in prev_snap with this hash
. in both cases when prev_snap object not found in curr_snap then the chunk is modified/removed and when curr_snap object not found in prev_snap then chunk is added/modified