# ğŸ“ Synclet

> A fast, intelligent, chunk-based file sync and backup tool, powered by **Content Defined Chunking (CDC)**.

---

## ğŸš€ Overview

**Synclet** is a custom file synchronization protocol that detects file-level and chunk-level changes using **rolling hashes** and **SHA-256**. It's designed to efficiently sync modified chunks only, rather than entire files, saving bandwidth and storage. Inspired by tools like *rsync* and *Google Photos*, it keeps metadata snapshots and supports bidirectional sync using a robust and extensible protocol.

---

## ğŸ” How It Works

### ğŸ“¸ Snapshot Creation

A snapshot is a metadata structure describing all files and their chunk-level content using SHA-256 hashes.

#### âœ… Steps:

1. For each file, read using a **sliding window** (`w` bytes).
2. Calculate a **rolling hash** (like Rabin-Karp) for the window.
3. When `rolling_hash % N == 0`, a **chunk boundary** is detected.
4. Generate a SHA-256 hash for the chunk and record it in the snapshot.

> âœ… Weak hash (rolling) detects boundaries, strong hash (SHA-256) confirms uniqueness.

#### âš  Why not fixed-size chunks?

Fixed-size chunks fail when even a small change shifts all data forward. CDC detects natural boundaries, minimizing reuploads for small edits.

---

## ğŸ”„ Change Detection Logic

Each chunk has metadata:

```json
{
  "offset": 0,
  "chunk_size": 1024,
  "chunk_no": 2,
  "hash": "<sha256>"
}
```

### ğŸ” Whatâ€™s considered modified?

* âœ… `hash` â€” definitive change indicator.
* ğŸš« `offset` or `chunk_no` alone are **not** sufficient to consider a chunk modified.

---

## ğŸ“¡ Protocol Design

Every sync action is represented by a `TYPE` and associated `PAYLOAD`.

### âœ‰ï¸ Protocol Message Types

| Type             | Description               | Payload | Raw Data |
| ---------------- | ------------------------- | ------- | -------- |
| `MODIFIED_CHUNK` | Existing chunk modified   | âœ…       | âœ…        |
| `FILE_CREATE`    | New file created          | âœ…       | âŒ        |
| `FILE_REMOVE`    | File deleted              | âœ…       | âŒ        |
| `FILE_RENAME`    | File renamed              | âœ…       | âŒ        |
| `FILES_CREATE`   | Multiple file creation    | âœ…       | âŒ        |
| `FILES_REMOVE`   | Multiple file deletions   | âœ…       | âŒ        |
| `SEND_FILE`      | Sending full file         | âœ…       | âŒ        |
| `REQ_CHUNK`      | Request specific chunk    | âœ…       | âŒ        |
| `SEND_CHUNK`     | Chunk data in response    | âœ…       | âœ…        |
| `REQ_SNAP`       | Request peer snapshot     | âŒ       | âŒ        |
| `DATA_SNAP`      | Send complete snapshot    | âœ…       | âŒ        |

---

## ğŸ“ Snapshot Format

```json
{
  "version": "filename|size|offset:chunk_size:chunk_hash",
  "files": [
    {
      "filename": "docs/report.txt",
      "size": 12345,
      "mtime": 1717100000,
      "chunks": {
        "<sha256>": {
          "chunk_no": 1,
          "hash": "<sha256>",
          "offset": 0,
          "chunk_size": 4096
        }
      }
    }
  ]
}
```

---

## â›“ Copying from Original to Temp File

To reconstruct modified files:

```json
chunks = [
  { "offset": 10, "size": 10 },
  { "offset": 30, "size": 40 },
  { "offset": 100, "size": 50 }
]
```

Steps:

* Copy original data between modified chunks.
* Insert new chunk data where required.
* Combine to form final temp file.

---

## ğŸ”° Initial Sync Strategy

### When starting from scratch:

1. Client checks for local `peer-snap-file.json`.
2. If absent, client sends `REQ_SNAP` to server.
3. Server replies with `DATA_SNAP`.
4. Client compares snapshots to:

   * Add missing files to server.
   * Fetch new/updated files from server.
   * Delete obsolete files (if server is outdated).

### Conflict Resolution:

* Use `mtime` to resolve direction of sync:

  * Client newer â†’ upload delta chunks.
  * Server newer â†’ fetch delta chunks.
* Delta chunks stored temporarily in `[filename]_dir/chunk-offset.bin`.

---

## ğŸ§¹ Cleaning Noisy Events (Under Consideration)

To debounce filesystem noise:

```ts
HashMap<filename, {
  last_event,
  last_time,
  timer_active,
  scheduled_action
}>
```

This avoids redundant syncs when rapid file system events (e.g., save triggers modify + delete + modify) occur.

---

## ğŸ§  Design Inspirations

* **rsync**: for delta-based sync
* **Bup/Duplicacy**: for snapshot design
* **Google Photos**: for metadata-based intelligent organization
* **Telegram**: potential channel storage

---

## ğŸ¤ Contribute

Feel free to suggest features, report issues, or create pull requests!

---